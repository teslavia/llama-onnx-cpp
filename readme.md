# Llama-2 C++ Inference on Mac (ONNX Runtime GenAI)

æœ¬é¡¹ç›®è®°å½•äº†åœ¨ Apple Silicon ç¯å¢ƒä¸‹ï¼Œå¦‚ä½•å°† Llama-2-7B-Chat æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œå¹¶åŸºäºå¾®è½¯ **ONNX Runtime GenAI (C++)** åº“å¼€å‘é«˜æ€§èƒ½ã€æ”¯æŒå¤šè½®å¯¹è¯çš„æœ¬åœ°æ¨ç†ç¨‹åºã€‚

## âœ¨ é¡¹ç›®äº®ç‚¹

- **é«˜æ€§èƒ½**: é’ˆå¯¹ M4 èŠ¯ç‰‡ä¼˜åŒ–ï¼Œä½¿ç”¨ Int4 é‡åŒ–ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨å¹¶æå‡æ¨ç†é€Ÿåº¦ã€‚
- **çº¯ C++ å®ç°**: æ‘†è„± Python ä¾èµ–ï¼Œåˆ©ç”¨åº•å±‚ C API å®ç°é«˜æ•ˆæ¨ç†ã€‚
- **å¤šè½®å¯¹è¯**: å®ç°äº† KV Cache çš„æŒä¹…åŒ–ç®¡ç†ï¼Œæ”¯æŒè¿ç»­å¯¹è¯ï¼ˆChat Modeï¼‰ã€‚
- **æœ€æ–° API é€‚é…**: è§£å†³äº† onnxruntime-genai æœ€æ–°ç‰ˆæœ¬ (v0.6.0+) API å˜åŠ¨å¸¦æ¥çš„å…¼å®¹æ€§é—®é¢˜ã€‚

## ğŸ›  å‰ç½®è¦æ±‚

- **ç¡¬ä»¶**: Mac Mini M4 Ultra (æˆ– M1/M2/M3 ç³»åˆ— Mac)
- **ç³»ç»Ÿ**: macOS Sequoia (æˆ–æ›´æ–°ç‰ˆæœ¬)
- **å·¥å…·**:
  - Xcode Command Line Tools
  - CMake (brew install cmake)
  - Python 3.10+ (ç”¨äºæ¨¡å‹å¯¼å‡º)
  - Hugging Face Access Token (ç”¨äºä¸‹è½½ Llama-2)

## ğŸ“‚ é¡¹ç›®ç»“æ„

```bash
.
â”œâ”€â”€ lib/                        # ä¾èµ–åº“ç›®å½•
â”‚   â”œâ”€â”€ include/                # å¤´æ–‡ä»¶ (ort_genai_c.h)
â”‚   â”œâ”€â”€ libonnxruntime-genai.dylib
â”‚   â””â”€â”€ libonnxruntime.dylib    # æ ¸å¿ƒè¿è¡Œæ—¶åº“
â”œâ”€â”€ model-onnx/                 # å¯¼å‡ºçš„ Int4 ONNX æ¨¡å‹
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.cpp                # ä¸»ç¨‹åºæºç  (æ”¯æŒå¤šè½®å¯¹è¯)
â”œâ”€â”€ CMakeLists.txt              # æ„å»ºé…ç½®
â””â”€â”€ README.md
```

## ğŸš€ æ­¥éª¤ä¸€ï¼šæ¨¡å‹å¯¼å‡ºä¸é‡åŒ–

ä½¿ç”¨ onnxruntime-genai çš„ Python å·¥å…·å°† Hugging Face æ ¼å¼çš„æ¨¡å‹è½¬æ¢ä¸ºä¼˜åŒ–çš„ ONNX æ ¼å¼ã€‚

1. **å®‰è£…ä¾èµ–**:

   ```bash
   pip install numpy onnxruntime-genai huggingface_hub
   ```

2. **ç™»å½• Hugging Face** (Llama-2 æ˜¯é—¨æ§æ¨¡å‹ï¼Œéœ€å…ˆç”³è¯·æƒé™):

   ```bash
   huggingface-cli login
   ```

3. **å¯¼å‡ºå¹¶é‡åŒ– (Int4)**:

   ```bash
   # -p int4: ä½¿ç”¨ 4-bit é‡åŒ– (æ¨è Apple Silicon ä½¿ç”¨)
   # -e cpu: ARM CPU æ”¯æŒ NEON æŒ‡ä»¤é›†åŠ é€Ÿ
   python3 -m onnxruntime_genai.models.builder -m meta-llama/Llama-2-7b-chat-hf -o ./model-onnx -p int4 -e cpu
   ```

## ğŸ’» æ­¥éª¤äºŒï¼šC++ ç¯å¢ƒé…ç½®

1. ä» [ONNX Runtime GenAI GitHub](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fonnxruntime-genai) ä¸‹è½½æˆ–ç¼–è¯‘é€‚ç”¨äº macOS ARM64 çš„åº“æ–‡ä»¶ã€‚
2. å°†ç¼–è¯‘å¥½çš„ libonnxruntime-genai.dylib å’Œä¾èµ–çš„ libonnxruntime.dylib æ”¾å…¥é¡¹ç›®çš„ lib/ ç›®å½•ã€‚
3. å°†å¤´æ–‡ä»¶ ort_genai_c.h æ”¾å…¥ lib/include/ã€‚

## âš™ï¸ æ­¥éª¤ä¸‰ï¼šç¼–è¯‘ä¸æ„å»º

ä½¿ç”¨äº†é€‚é…æœ€æ–°ç‰ˆ API (AppendTokenSequences æ¥å£) çš„ä»£ç é€»è¾‘ã€‚

```bash
mkdir build && cd build
cmake ..
make
```

## â–¶ï¸ æ­¥éª¤å››ï¼šè¿è¡Œæ¨ç†

è¿è¡Œç”Ÿæˆçš„å¯æ‰§è¡Œæ–‡ä»¶ï¼Œå¹¶æŒ‡å®šæ¨¡å‹ç›®å½•è·¯å¾„ï¼š

```bash
# ç¡®ä¿åœ¨ build ç›®å½•ä¸‹è¿è¡Œ
./llama_inference ../model-onnx
```

### äº¤äº’ç¤ºä¾‹

```bash
Loading model from: ../model-onnx...
Model loaded! Type '/exit' to quit.

>>> User: Hello, explain quantum computing like I'm 5.
>>> Llama: Sure! Imagine you have a magic coin that can be heads and tails at the same time...

>>> User: What was the first thing I asked you?
>>> Llama: You asked me to explain quantum computing simply.
```

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1. åŠ¨æ€åº“åŠ è½½å¤±è´¥ (Image not found / abort)

**ç°è±¡**: è¿è¡Œæ—¶æç¤º dyld: Library not loaded æˆ–ç›´æ¥ abortã€‚
**åŸå› **: ç¨‹åºæ‰¾ä¸åˆ°ä¾èµ–çš„ .dylib æ–‡ä»¶ã€‚
**è§£å†³**:

- ç¡®ä¿ libonnxruntime.dylib å’Œ libonnxruntime-genai.dylib éƒ½åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚
- åœ¨ CMake ä¸­é…ç½®äº† RPATHï¼Œæˆ–è€…æ‰‹åŠ¨å°†åº“æ–‡ä»¶å¤åˆ¶åˆ° build ç›®å½•æˆ– /usr/local/libã€‚

### 2. API ç¼–è¯‘é”™è¯¯ (SetInputSequences undefined)

**ç°è±¡**: ç¼–è¯‘æ—¶æŠ¥é”™ OgaGeneratorParamsSetInputSequences æœªå®šä¹‰ã€‚
**åŸå› **: å¾®è½¯æ›´æ–°äº† APIï¼Œå°†è¾“å…¥å¤„ç†ä» Params ä¸­åˆ†ç¦»ã€‚
**è§£å†³**: æœ¬é¡¹ç›®å·²é€‚é…æ–°ç‰ˆ APIï¼Œä½¿ç”¨ OgaGenerator_AppendTokenSequences(generator, sequences) æ¥å¤„ç†è¾“å…¥ã€‚

### 3. å¤šè½®å¯¹è¯ä¸è®°å¿†ä¸Šä¸‹æ–‡

**åŸå› **: æ¯è½®å¯¹è¯é‡æ–°åˆ›å»ºäº† Generatorã€‚
**è§£å†³**: Generator å¯¹è±¡åœ¨å¾ªç¯å¤–åˆ›å»ºï¼Œå¾ªç¯å†…ä»…ä½¿ç”¨ Append è¿½åŠ æ–°çš„ Tokenï¼Œä»è€Œä¿æŒ KV Cache çŠ¶æ€ã€‚

## ğŸ”— å‚è€ƒèµ„æ–™

- [Microsoft ONNX Runtime GenAI](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fonnxruntime-genai)
- [Meta Llama 2](https://www.google.com/url?sa=E&q=https%3A%2F%2Fhuggingface.co%2Fmeta-llama)